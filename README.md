# LLMs Reading LLMs: Exploring Hugging Face Models with NotebookLM

This project explores how [Googleâ€™s NotebookLM](https://notebooklm.google.com/notebook/e5fc39aa-6d61-428f-b2be-951efd083175), an AI-powered research assistant, can be used to interactively question and analyze model documentation from Hugging Faceâ€™s Transformers library.

I uploaded multiple model cards (such as FLAN-T5, DistilBERT, and GPT-2) into NotebookLM and asked it a series of technical, comparative, and ethical questions. This unique setup allows us to evaluate how a document-grounded LLM assistant interprets real-world model documentation without hallucination.


## Objective

- Use NotebookLM to explore the reasoning, factual accuracy, and limitations of well-known Hugging Face models.
- Assess how grounded language models respond to prompts using only provided documentation.
- Identify risks like hallucination, bias, or gaps in documentation-based answers.

---

## Methodology

1. Selected 3 popular model cards: `flan-t5`, `gpt-2`, and `distilbert-base-uncased`.
2. Uploaded model documentation into a new NotebookLM notebook.
3. Asked curated questions about:
   - Model behavior (e.g., summarization)
   - Factual generation and hallucination risk
   - Comparison between models
   - Documentation gaps
4. Collected screenshots and generated answers.

---

## Sample Prompts

> Why did Hugging Face include GPT-2 despite known risks?
>  Compare hallucination risks in GPT-2 vs FLAN-T5.
> Why canâ€™t NotebookLM give details about GPT-4.1?
> Based on source docs, which model is safer for factual tasks?

All prompts are categorized in the [NotebookLm_Prompts.txt](./NotebookLm_Prompts.txt) file.

---

## Screenshots

## ðŸ“¸ Screenshots

### Summary Response Example
![Summary Response](https://github.com/kalyan678/llms-reading-huggingface-with-notebooklm/raw/main/Screenshot_1.png)

### Hallucination Prompt Result
![Hallucination Prompt](https://github.com/kalyan678/llms-reading-huggingface-with-notebooklm/raw/main/Screenshot_3.png)


---

## Key Takeaways

- NotebookLM can offer grounded and coherent summaries **only if the input sources contain the required information**.
- It performs well in *intra-document inference*, but fails when asked about *external models (e.g., GPT-4.1)* not present in the sources.
- Model documentation varies in completeness, affecting response quality.

---

## Folder Structure
```
llms-reading-llms/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Notebooklm_prompts.txt
â”œâ”€â”€ models_info/
â”‚ â”œâ”€â”€ flan-t5-summary.md
â”‚ â”œâ”€â”€ gpt-2-card.txt
â”œâ”€â”€ screenshots/
â”‚ â”œâ”€â”€ summary-response.png
â”‚ â”œâ”€â”€ comparison-question.png

```
